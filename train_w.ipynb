{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils.exft import exFTModel\n",
    "from utils.wmdl import Composer\n",
    "from utils.nntool import UniDataset, SimpTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_ = exFTModel(r\"./ft_model/cczh128.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll process data here later\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv()    # *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata, ydata = [], []\n",
    "\n",
    "_subs: str\n",
    "for _subs, compd in zip(df[\"subs\"], df[\"compd\"]):   # *\n",
    "    subs = tuple([ torch.from_numpy( ft_.get_word_vec(i) ) for i in _subs.split(\"+\") ])\n",
    "    compd = ft_.get_word_vec(compd)\n",
    "    Xdata.append(subs); ydata.append( torch.from_numpy(compd) )\n",
    "\n",
    "ydata = torch.stack(ydata)\n",
    "\n",
    "print(Xdata, \"\\n\", ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xts, ytr, yts = train_test_split(Xdata, ydata, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13072bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SimpTrainer(\n",
    "    mdl := Composer(\n",
    "        128,\n",
    "        32,\n",
    "    ),\n",
    "    (\n",
    "        UniDataset(Xtr, ytr)\n",
    "        .to_dataloader(batch_size = 10, _collate_fn = lambda x: x)\n",
    "    ),\n",
    "    nn.MSELoss(),       # why not use Cosine Loss (..) here ?\n",
    "    opt := optim.AdamW(\n",
    "        mdl.parameters(),\n",
    "        lr = 3e-4,\n",
    "        weight_decay = 1E-2,\n",
    "    )\n",
    ")\n",
    "\n",
    "sched = StepLR(opt, step_size = 5, gamma = 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfc687",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    ls_tr = trainer.train_epoch(verbose = f\"epoch - {i}\")\n",
    "    sched.step()\n",
    "    \n",
    "    if i % 10 == 9:\n",
    "        ls_ts = trainer.eval_(Xts, yts)\n",
    "        print(f\"checkpoint-()  tr:{ls_tr: .4f}; ts:{ls_ts: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3229af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./models/w0.bin\", \"wb\") as f: dump(mdl, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
